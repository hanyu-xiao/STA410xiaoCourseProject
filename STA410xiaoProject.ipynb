{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyw2HbEN+k3RySXdhfrS/d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchbnn numpy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ppnFOfjgzesD",
        "outputId": "184b85b2-3508-495b-e714-21ccba4a8d1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting torchbnn\n",
            "  Downloading torchbnn-1.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchbnn-1.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: torchbnn, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchbnn-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "daP_8xI1zLjo",
        "outputId": "2c4ee197-bdbc-44e7-dd99-e98cb3e9392e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Steps=85736, Best=85736, Reward=-3664.15\n",
            "Episode 1: Steps=59485, Best=59485, Reward=-2548.04\n"
          ]
        }
      ],
      "source": [
        "from pickle import TRUE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchbnn as bnn\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "from matplotlib import colors\n",
        "\n",
        "# ===== CONSTANTS =====\n",
        "\n",
        "# Maze configuration\n",
        "SIMPLE_WALLS = False  # Use the predefined simple maze layout or generate maze walls procedurally\n",
        "MAZE_SIZE = 15 # Side length of the square maze, should be odd for optimal computation time\n",
        "if SIMPLE_WALLS:\n",
        "    WALL_ROW_1 = round(MAZE_SIZE / 3)      # Wall at 1/3 of maze height\n",
        "    WALL_ROW_2 = round(2 * MAZE_SIZE / 3)  # Wall at 2/3 of maze height\n",
        "    GAP_COL_1 = round(2 * MAZE_SIZE / 3)   # Gap in first wall\n",
        "    GAP_COL_2 = round(1 * MAZE_SIZE / 3)   # Gap in second wall\n",
        "GOAL_POS = (MAZE_SIZE - 1, MAZE_SIZE - 1)  # Bottom-right corner\n",
        "START_POS = (0, 0)  # Top-left corner\n",
        "REPRODUCIBLE = False # set to True to have the maze be the same\n",
        "\n",
        "if REPRODUCIBLE:\n",
        "    np.random.seed(410)\n",
        "\n",
        "# Training parameters\n",
        "MAX_EPISODES = 500 # Maximum number of training cycles, typically PATIENCE ends up being the stopping factor to training\n",
        "PATIENCE = 10  # Early stopping patience, after this number of episodes without improvement the training ends\n",
        "PLOT_INTERVAL = 1  # Plot every N episodes\n",
        "ANIMATION_INTERVAL = 300  # ms between frames\n",
        "\n",
        "# Reward parameters\n",
        "GOAL_REWARD = 1\n",
        "STEP_PENALTY = -0.01\n",
        "DISTANCE_REWARD_FACTOR = 0.1  # Scaling factor for distance-based reward\n",
        "\n",
        "# Network parameters\n",
        "LEARNING_RATE = 0.01\n",
        "PRIOR_SIGMA = 0.1\n",
        "HIDDEN_SIZE = 32\n",
        "\n",
        "# ===== MAZE CLASS =====\n",
        "class Maze:\n",
        "    def __init__(self, size=MAZE_SIZE):\n",
        "        self.size = size\n",
        "        self.grid = np.zeros((size, size))\n",
        "        self.goal = GOAL_POS\n",
        "        self.walls = self._create_walls()\n",
        "        self.reset()\n",
        "\n",
        "    def _create_walls(self):\n",
        "        \"\"\"Generate a more branchy maze using randomized backtracking + controlled bias\"\"\"\n",
        "        if SIMPLE_WALLS:\n",
        "            walls = set()\n",
        "            for y in range(self.size):\n",
        "                if y != GAP_COL_1:\n",
        "                    walls.add((WALL_ROW_1, y))\n",
        "            for y in range(self.size):\n",
        "                if y != GAP_COL_2:\n",
        "                    walls.add((WALL_ROW_2, y))\n",
        "            return walls\n",
        "\n",
        "        # Ensure odd size for better maze structure\n",
        "        if self.size % 2 == 0:\n",
        "            self.size += 1\n",
        "\n",
        "        maze = np.ones((self.size, self.size), dtype=np.int8)\n",
        "        visited = set()\n",
        "        stack = [(0, 0)]\n",
        "        maze[0, 0] = 0\n",
        "        visited.add((0, 0))\n",
        "\n",
        "        def neighbors(x, y):\n",
        "            dirs = [(2, 0), (-2, 0), (0, 2), (0, -2)]\n",
        "            np.random.shuffle(dirs)\n",
        "            for dx, dy in dirs:\n",
        "                nx, ny = x + dx, y + dy\n",
        "                if 0 <= nx < self.size and 0 <= ny < self.size and (nx, ny) not in visited:\n",
        "                    yield (nx, ny, x + dx // 2, y + dy // 2)  # wall between\n",
        "\n",
        "        while stack:\n",
        "            x, y = stack[-1]\n",
        "            neighbor_list = list(neighbors(x, y))\n",
        "            if neighbor_list:\n",
        "                # Branchy tweak: instead of always taking the last cell (DFS),\n",
        "                # sometimes randomly jump back in the stack\n",
        "                if np.random.rand() < 0.2:  # 20% chance to jump for branching\n",
        "                    x, y = stack[np.random.randint(0, len(stack))]\n",
        "                    neighbor_list = list(neighbors(x, y))\n",
        "                    if not neighbor_list:\n",
        "                        continue\n",
        "\n",
        "                nx, ny, wx, wy = neighbor_list[0]\n",
        "                maze[nx, ny] = 0\n",
        "                maze[wx, wy] = 0\n",
        "                visited.add((nx, ny))\n",
        "                stack.append((nx, ny))\n",
        "            else:\n",
        "                stack.pop()\n",
        "\n",
        "        # Clear goal cell just in case\n",
        "        maze[self.goal[0]][self.goal[1]] = 0\n",
        "\n",
        "        # Convert to wall set\n",
        "        walls = set()\n",
        "        for i in range(self.size):\n",
        "            for j in range(self.size):\n",
        "                if maze[i, j] == 1:\n",
        "                    walls.add((i, j))\n",
        "\n",
        "        return walls\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = START_POS\n",
        "        return self.agent_pos\n",
        "\n",
        "    def calculate_distance_to_goal(self, pos):\n",
        "        \"\"\"Calculate Manhattan distance to goal\"\"\"\n",
        "        return abs(pos[0] - self.goal[0]) + abs(pos[1] - self.goal[1])\n",
        "\n",
        "    def step(self, action):\n",
        "        x, y = self.agent_pos\n",
        "        new_x, new_y = x, y\n",
        "\n",
        "        if action == 0 and x > 0:           new_x -= 1  # Up\n",
        "        elif action == 1 and y < self.size-1: new_y += 1  # Right\n",
        "        elif action == 2 and x < self.size-1: new_x += 1  # Down\n",
        "        elif action == 3 and y > 0:           new_y -= 1  # Left\n",
        "\n",
        "        # Check for wall collisions\n",
        "        if (new_x, new_y) not in self.walls:\n",
        "            prev_distance = self.calculate_distance_to_goal(self.agent_pos)\n",
        "            self.agent_pos = (new_x, new_y)\n",
        "            new_distance = self.calculate_distance_to_goal(self.agent_pos)\n",
        "            distance_reward = (prev_distance - new_distance) * DISTANCE_REWARD_FACTOR\n",
        "        else:\n",
        "            distance_reward = -0.1  # Small penalty for hitting walls\n",
        "\n",
        "        done = (self.agent_pos == self.goal)\n",
        "\n",
        "        if done:\n",
        "            reward = GOAL_REWARD\n",
        "        else:\n",
        "            reward = distance_reward + STEP_PENALTY\n",
        "\n",
        "        return self.agent_pos, reward, done\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"Visualize maze with solid walls using imshow\"\"\"\n",
        "        # Create grid: 0=empty, 1=wall, 2=agent, 3=goal\n",
        "        vis_grid = np.zeros((self.size, self.size))\n",
        "\n",
        "        # Mark walls\n",
        "        for (x, y) in self.walls:\n",
        "            vis_grid[x, y] = 1\n",
        "\n",
        "        # Mark agent and goal\n",
        "        vis_grid[self.agent_pos] = 2\n",
        "        vis_grid[self.goal] = 3\n",
        "\n",
        "        # Create custom colormap\n",
        "        cmap = colors.ListedColormap(['white', 'black', 'red', 'green'])\n",
        "        bounds = [0, 1, 2, 3, 4]\n",
        "        norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.imshow(vis_grid, cmap=cmap, norm=norm)\n",
        "\n",
        "        # Add legend\n",
        "        plt.plot([], [], 's', color='black', markersize=10, label='Walls')\n",
        "        plt.plot([], [], 'o', color='red', markersize=8, label='Agent')\n",
        "        plt.plot([], [], '*', color='green', markersize=12, label='Goal')\n",
        "        plt.legend(loc='upper right')\n",
        "\n",
        "        plt.title(\"Maze with Solid Walls\")\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.show()\n",
        "\n",
        "# ===== BAYESIAN DQN =====\n",
        "class BayesianDQN(torch.nn.Module):\n",
        "    def __init__(self, state_dim=2, action_dim=4):\n",
        "        super().__init__()\n",
        "        self.fc1 = bnn.BayesLinear(\n",
        "            prior_mu=0,\n",
        "            prior_sigma=PRIOR_SIGMA,\n",
        "            in_features=state_dim,\n",
        "            out_features=HIDDEN_SIZE\n",
        "        )\n",
        "        self.fc2 = bnn.BayesLinear(\n",
        "            prior_mu=0,\n",
        "            prior_sigma=PRIOR_SIGMA,\n",
        "            in_features=HIDDEN_SIZE,\n",
        "            out_features=action_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ===== TRAINING AND ANIMATION =====\n",
        "def train_and_animate(maze, episodes=MAX_EPISODES, early_stop=True):\n",
        "    model = BayesianDQN()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = bnn.BKLLoss(reduction='mean', last_layer_only=False)\n",
        "\n",
        "    uncertainty_history = []\n",
        "    path_history = []  # To store agent paths for each episode\n",
        "    episode_metrics = []\n",
        "    best_steps = float('inf')\n",
        "    no_improve = 0\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        state = maze.reset()\n",
        "        done = False\n",
        "        steps = 0\n",
        "        episode_reward = 0\n",
        "        path = [state]  # Track the agent's path\n",
        "\n",
        "        while not done:\n",
        "            state_tensor = torch.FloatTensor(state)\n",
        "            q_values = model(state_tensor)\n",
        "            action = torch.argmax(q_values).item()\n",
        "            next_state, reward, done = maze.step(action)\n",
        "\n",
        "            episode_reward += reward\n",
        "            path.append(next_state)  # Record each step\n",
        "            state = next_state\n",
        "\n",
        "            # Calculate target with discount factor\n",
        "            with torch.no_grad():\n",
        "                if done:\n",
        "                    target = torch.tensor(reward, dtype=torch.float32)\n",
        "                else:\n",
        "                    next_q_values = model(torch.FloatTensor(next_state))\n",
        "                    target = reward + 0.99 * torch.max(next_q_values)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = torch.nn.MSELoss()(q_values[action], target) + criterion(model)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            steps += 1\n",
        "\n",
        "        if early_stop:\n",
        "            if steps < best_steps:\n",
        "                best_steps = steps\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "\n",
        "            if no_improve >= PATIENCE:\n",
        "                print(f\"Early stopping at episode {ep} (no improvement for {PATIENCE} episodes)\")\n",
        "                break\n",
        "\n",
        "        if ep % PLOT_INTERVAL == 0:\n",
        "            uncertainty_map = generate_uncertainty_map(model, maze)\n",
        "            uncertainty_history.append(uncertainty_map)\n",
        "            path_history.append(path)  # Save the path for this episode\n",
        "            episode_metrics.append((ep, steps, best_steps, episode_reward))\n",
        "            print(f\"Episode {ep}: Steps={steps}, Best={best_steps}, Reward={episode_reward:.2f}\")\n",
        "\n",
        "    return create_animation(uncertainty_history, path_history, episode_metrics, maze)\n",
        "\n",
        "def generate_uncertainty_map(model, maze):\n",
        "    \"\"\"Generate uncertainty map with walls marked as -1\"\"\"\n",
        "    uncertainty_map = np.zeros((maze.size, maze.size))\n",
        "    for x in range(maze.size):\n",
        "        for y in range(maze.size):\n",
        "            if (x, y) in maze.walls:\n",
        "                uncertainty_map[x, y] = -1  # Special value for walls\n",
        "            else:\n",
        "                state = torch.FloatTensor([x, y])\n",
        "                q_samples = [model(state).detach().numpy() for _ in range(10)]\n",
        "                uncertainty_map[x, y] = np.std(q_samples, axis=0).mean()\n",
        "    return uncertainty_map\n",
        "\n",
        "\n",
        "\n",
        "def create_animation(uncertainty_history, path_history, episode_metrics, maze):\n",
        "    \"\"\"Create compact animation with uncertainty heatmap and path visualization\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={'width_ratios': [1, 1]})\n",
        "    plt.close()\n",
        "\n",
        "    # ===== Uncertainty Plot (Left) =====\n",
        "    cmap = plt.cm.hot.copy()\n",
        "    cmap.set_bad('black')\n",
        "    cmap.set_under('blue')\n",
        "    cmap.set_over('green')\n",
        "\n",
        "    masked_data = np.ma.masked_where(\n",
        "        (uncertainty_history[0] == -1) | (uncertainty_history[0] == -2) | (uncertainty_history[0] == -3),\n",
        "        uncertainty_history[0]\n",
        "    )\n",
        "    im1 = ax1.imshow(masked_data, cmap=cmap, vmin=0, vmax=1)\n",
        "\n",
        "    # Add static elements\n",
        "    wall_grid = np.zeros((maze.size, maze.size))\n",
        "    for (x,y) in maze.walls:\n",
        "        wall_grid[x,y] = 1\n",
        "    ax1.imshow(wall_grid, cmap=colors.ListedColormap(['none', 'black']), alpha=0.3)\n",
        "\n",
        "    # Add start and goal markers\n",
        "    start_marker = plt.Rectangle((START_POS[1]-0.5, START_POS[0]-0.5), 1, 1, color='blue', alpha=1)\n",
        "    goal_marker = plt.Rectangle((GOAL_POS[1]-0.5, GOAL_POS[0]-0.5), 1, 1, color='green', alpha=1)\n",
        "    ax1.add_patch(start_marker)\n",
        "    ax1.add_patch(goal_marker)\n",
        "\n",
        "    ax1.set_title(\"Q Uncertainty Heatmap\")\n",
        "    cbar1 = fig.colorbar(im1, ax=ax1, label='Std Dev', fraction=0.046, pad=0.04)\n",
        "\n",
        "    # ===== Path Visualization (Right) =====\n",
        "    path = path_history[0]\n",
        "    path_grid = np.zeros((maze.size, maze.size)) - 1\n",
        "    for step, (x,y) in enumerate(path):\n",
        "        path_grid[x,y] = step\n",
        "\n",
        "    norm = colors.Normalize(vmin=0, vmax=max(1, len(path)-1))\n",
        "    im2 = ax2.imshow(np.ma.masked_where(path_grid == -1, path_grid),\n",
        "                    cmap='viridis', norm=norm)\n",
        "\n",
        "    # Add walls, start, and goal\n",
        "    ax2.imshow(wall_grid, cmap=colors.ListedColormap(['none', 'black']), alpha=0.3)\n",
        "    ax2.add_patch(plt.Rectangle((START_POS[1]-0.5, START_POS[0]-0.5), 1, 1, color='blue', alpha=0.5))\n",
        "    ax2.add_patch(plt.Rectangle((GOAL_POS[1]-0.5, GOAL_POS[0]-0.5), 1, 1, color='green', alpha=0.5))\n",
        "\n",
        "    ax2.set_title(\"Agent Path\")\n",
        "    cbar2 = fig.colorbar(im2, ax=ax2, label='Step', fraction=0.046, pad=0.04)\n",
        "\n",
        "    # Main title with tighter spacing\n",
        "    main_title = fig.suptitle(\n",
        "        f'Episode {episode_metrics[0][0]} | Steps: {episode_metrics[0][1]} (Best: {episode_metrics[0][2]}) | Reward: {episode_metrics[0][3]:.2f}',\n",
        "        y=.95,\n",
        "        fontsize=12\n",
        "    )\n",
        "\n",
        "    # Adjust layout\n",
        "    plt.tight_layout(pad=.01)\n",
        "    fig.subplots_adjust(top=0.9, left=.06, bottom=.06, right=.92, wspace=0.25)\n",
        "\n",
        "    def update(frame):\n",
        "        # Update uncertainty plot\n",
        "        masked_data = np.ma.masked_where(\n",
        "            (uncertainty_history[frame] == -1) | (uncertainty_history[frame] == -2) | (uncertainty_history[frame] == -3),\n",
        "            uncertainty_history[frame]\n",
        "        )\n",
        "        im1.set_array(masked_data)\n",
        "\n",
        "        # Update path plot\n",
        "        path = path_history[frame]\n",
        "        path_grid = np.zeros((maze.size, maze.size)) - 1\n",
        "        for step, (x,y) in enumerate(path):\n",
        "            path_grid[x,y] = step\n",
        "        im2.set_array(np.ma.masked_where(path_grid == -1, path_grid))\n",
        "        im2.set_norm(colors.Normalize(vmin=0, vmax=max(1, len(path)-1)))\n",
        "\n",
        "        # Update title\n",
        "        ep, steps, best, reward = episode_metrics[frame]\n",
        "        main_title.set_text(f'Episode {ep} | Steps: {steps} (Best: {best}) | Reward: {reward:.2f}')\n",
        "\n",
        "        return im1, im2, main_title\n",
        "\n",
        "    ani = FuncAnimation(\n",
        "        fig,\n",
        "        update,\n",
        "        frames=len(uncertainty_history),\n",
        "        interval=ANIMATION_INTERVAL,\n",
        "        blit=False\n",
        "    )\n",
        "\n",
        "    return HTML(ani.to_jshtml())\n",
        "\n",
        "# ===== MAIN =====\n",
        "if __name__ == \"__main__\":\n",
        "    maze = Maze()\n",
        "    maze.render()  # Show initial maze with solid walls\n",
        "    animation = train_and_animate(maze)\n",
        "    display(animation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In scripts: Use ani.save('uncertainty_evolution.mp4')"
      ],
      "metadata": {
        "id": "atrOKDLku3Ol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}